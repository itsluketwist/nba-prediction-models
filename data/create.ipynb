{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation\n",
    "\n",
    "This notebook will process the \n",
    "[NBA Database](https://www.kaggle.com/datasets/wyattowalsh/basketball/data) dataset from \n",
    "[Kaggle](https://www.kaggle.com/), and construct multiple datasets of sequential NBA result data, \n",
    "leading up to a game between 2 teams.\n",
    "\n",
    "The database must be downloaded and stored in `data/` to continue.\n",
    "\n",
    "Several training, testing and evaluation datasets will be created - \n",
    "they are fully described in `data/README.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "\n",
    "db = sqlite3.connect(\"nba.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('22009', '22010', '22011', '22013', '22014', '22015', '22016', '22017', '22018', '22019', '22020', '22021', '22022')\n"
     ]
    }
   ],
   "source": [
    "# get all seasons in the sample\n",
    "season_start = \"2009-10-01 00:00:00\"\n",
    "season_type = \"Regular Season\"\n",
    "season_query = f\"\"\"\n",
    "SELECT\n",
    "    DISTINCT season_id \n",
    "FROM game \n",
    "WHERE \n",
    "    game_date > '{season_start}' \n",
    "    AND season_type = '{season_type}';\n",
    "\"\"\"\n",
    "\n",
    "season_ids_df = pd.read_sql_query(sql=season_query, con=db)\n",
    "season_ids = tuple(season_ids_df.season_id.values)\n",
    "print(season_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data into a single table\n",
    "create_full_game_data = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS full_game_data AS\n",
    "SELECT *\n",
    "FROM game \n",
    "    INNER JOIN line_score USING (game_id)\n",
    "    INNER JOIN other_stats USING (game_id)\n",
    "WHERE \n",
    "    season_id IN {season_ids};\n",
    "\"\"\"\n",
    "\n",
    "with db:\n",
    "    _ = db.execute(create_full_game_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove table if re-running\n",
    "with db:\n",
    "    _ = db.execute(\"DROP TABLE per_team_game_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table containing all game data per team\n",
    "create_per_team_game_data = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS per_team_game_data AS\n",
    "\n",
    "SELECT \n",
    "    season_id AS season_id,\n",
    "    game_id,\n",
    "    \n",
    "    -- team info --\n",
    "    team_id_home AS team_id,\n",
    "    game_date_est AS date,\n",
    "    CASE WHEN wl_home = 'W' THEN 1 ELSE 0 END AS win,\n",
    "    1 AS home,\n",
    "    CASE WHEN ABS(pts_home - pts_away) <= 8 THEN 1 ELSE 0 END AS close_game,\n",
    "    CASE\n",
    "        WHEN COALESCE(pts_ot10_home, 0) != 0 THEN 10\n",
    "        WHEN COALESCE(pts_ot9_home, 0) != 0 THEN 9\n",
    "        WHEN COALESCE(pts_ot8_home, 0) != 0 THEN 8\n",
    "        WHEN COALESCE(pts_ot7_home, 0) != 0 THEN 7\n",
    "        WHEN COALESCE(pts_ot6_home, 0) != 0 THEN 6\n",
    "        WHEN COALESCE(pts_ot5_home, 0) != 0 THEN 5\n",
    "        WHEN COALESCE(pts_ot4_home, 0) != 0 THEN 4\n",
    "        WHEN COALESCE(pts_ot3_home, 0) != 0 THEN 3\n",
    "        WHEN COALESCE(pts_ot2_home, 0) != 0 THEN 2\n",
    "        WHEN COALESCE(pts_ot1_home, 0) != 0 THEN 1\n",
    "    ELSE 0 END AS ot_count,\n",
    "    team_wins_losses_home AS wins_losses,\n",
    "\n",
    "    -- line score\n",
    "    pts_qtr1_home AS q1_points,\n",
    "    pts_qtr2_home AS q2_points,\n",
    "    pts_qtr3_home AS q3_points,\n",
    "    pts_qtr4_home AS q4_points,\n",
    "    COALESCE(pts_ot1_home, 0) + COALESCE(pts_ot2_home, 0) + COALESCE(pts_ot3_home, 0) + COALESCE(pts_ot4_home, 0) + COALESCE(pts_ot5_home, 0) + COALESCE(pts_ot6_home, 0) + COALESCE(pts_ot7_home, 0) + COALESCE(pts_ot8_home, 0) + COALESCE(pts_ot9_home, 0) + COALESCE(pts_ot10_home, 0) AS ot_points,\n",
    "    pts_home AS final_points,\n",
    "\n",
    "    -- base stats --\n",
    "    fgm_home AS field_made,\n",
    "    fg_pct_home AS field_percent,\n",
    "    fg3m_home AS three_made,\n",
    "    fg3_pct_home AS three_percent,\n",
    "    ftm_home AS free_made,\n",
    "    ft_pct_home AS free_percent,\n",
    "    oreb_home AS offensive_rebounds,\n",
    "    dreb_home AS defensive_rebounds,\n",
    "    reb_home AS total_rebounds,\n",
    "    ast_home AS assists,\n",
    "    stl_home AS steals,\n",
    "    blk_home AS blocks,\n",
    "    tov_home AS turnovers,\n",
    "    pf_home AS fouls,\n",
    "    plus_minus_home AS plus_minus,\n",
    "\n",
    "    -- other stats --\n",
    "    pts_paint_home AS pts_paint,\n",
    "    pts_2nd_chance_home AS pts_2nd_chance,\n",
    "    pts_fb_home AS pts_fast_break,\n",
    "    largest_lead_home AS largest_lead\n",
    "\n",
    "FROM full_game_data\n",
    "\n",
    "UNION\n",
    "\n",
    "SELECT \n",
    "    season_id AS season_id,\n",
    "    game_id,\n",
    "    \n",
    "    -- team info --\n",
    "    team_id_away AS team_id,\n",
    "    game_date_est AS date,\n",
    "    CASE WHEN wl_home = 'W' THEN 0 ELSE 1 END AS win,\n",
    "    0 AS home,\n",
    "    CASE WHEN ABS(pts_home - pts_away) <= 8 THEN 1 ELSE 0 END AS close_game,\n",
    "    CASE\n",
    "        WHEN COALESCE(pts_ot10_away, 0) != 0 THEN 10\n",
    "        WHEN COALESCE(pts_ot9_away, 0) != 0 THEN 9\n",
    "        WHEN COALESCE(pts_ot8_away, 0) != 0 THEN 8\n",
    "        WHEN COALESCE(pts_ot7_away, 0) != 0 THEN 7\n",
    "        WHEN COALESCE(pts_ot6_away, 0) != 0 THEN 6\n",
    "        WHEN COALESCE(pts_ot5_away, 0) != 0 THEN 5\n",
    "        WHEN COALESCE(pts_ot4_away, 0) != 0 THEN 4\n",
    "        WHEN COALESCE(pts_ot3_away, 0) != 0 THEN 3\n",
    "        WHEN COALESCE(pts_ot2_away, 0) != 0 THEN 2\n",
    "        WHEN COALESCE(pts_ot1_away, 0) != 0 THEN 1\n",
    "    ELSE 0 END AS ot_count,\n",
    "    team_wins_losses_away AS wins_losses,\n",
    "\n",
    "    -- line score\n",
    "    pts_qtr1_away AS q1_points,\n",
    "    pts_qtr2_away AS q2_points,\n",
    "    pts_qtr3_away AS q3_points,\n",
    "    pts_qtr4_away AS q4_points,\n",
    "    COALESCE(pts_ot1_away, 0) + COALESCE(pts_ot2_away, 0) + COALESCE(pts_ot3_away, 0) + COALESCE(pts_ot4_away, 0) + COALESCE(pts_ot5_away, 0) + COALESCE(pts_ot6_away, 0) + COALESCE(pts_ot7_away, 0) + COALESCE(pts_ot8_away, 0) + COALESCE(pts_ot9_away, 0) + COALESCE(pts_ot10_away, 0) AS ot_points,\n",
    "    pts_away AS final_points,\n",
    "    \n",
    "    -- base stats --\n",
    "    fgm_away AS field_made,\n",
    "    fg_pct_away AS field_percent,\n",
    "    fg3m_away AS three_made,\n",
    "    fg3_pct_away AS three_percent,\n",
    "    ftm_away AS free_made,\n",
    "    ft_pct_away AS free_percent,\n",
    "    oreb_away AS offensive_rebounds,\n",
    "    dreb_away AS defensive_rebounds,\n",
    "    reb_away AS total_rebounds,\n",
    "    ast_away AS assists,\n",
    "    stl_away AS steals,\n",
    "    blk_away AS blocks,\n",
    "    tov_away AS turnovers,\n",
    "    pf_away AS fouls,\n",
    "    plus_minus_away AS plus_minus,\n",
    "\n",
    "    -- other stats --\n",
    "    pts_paint_away AS pts_paint,\n",
    "    pts_2nd_chance_away AS pts_2nd_chance,\n",
    "    pts_fb_away AS pts_fast_break,\n",
    "    largest_lead_away AS largest_lead\n",
    "\n",
    "FROM full_game_data;\n",
    "\"\"\"\n",
    "\n",
    "with db:\n",
    "    _ = db.execute(create_per_team_game_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26248, 34)\n",
      "['season_id' 'game_id' 'team_id' 'date' 'win' 'home' 'close_game'\n",
      " 'ot_count' 'wins_losses' 'q1_points' 'q2_points' 'q3_points' 'q4_points'\n",
      " 'ot_points' 'final_points' 'field_made' 'field_percent' 'three_made'\n",
      " 'three_percent' 'free_made' 'free_percent' 'offensive_rebounds'\n",
      " 'defensive_rebounds' 'total_rebounds' 'assists' 'steals' 'blocks'\n",
      " 'turnovers' 'fouls' 'plus_minus' 'pts_paint' 'pts_2nd_chance'\n",
      " 'pts_fast_break' 'largest_lead']\n"
     ]
    }
   ],
   "source": [
    "# load per-team game data into a dataframe\n",
    "team_data_df = pd.read_sql_query(\n",
    "    sql=\"SELECT * FROM per_team_game_data;\",\n",
    "    con=db,\n",
    ")\n",
    "\n",
    "# check size and columns\n",
    "print(team_data_df.shape)\n",
    "print(team_data_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26248, 35)\n",
      "['season_id' 'game_id' 'team_id' 'date' 'win' 'home' 'close_game'\n",
      " 'ot_count' 'q1_points' 'q2_points' 'q3_points' 'q4_points' 'ot_points'\n",
      " 'final_points' 'field_made' 'field_percent' 'three_made' 'three_percent'\n",
      " 'free_made' 'free_percent' 'offensive_rebounds' 'defensive_rebounds'\n",
      " 'total_rebounds' 'assists' 'steals' 'blocks' 'turnovers' 'fouls'\n",
      " 'plus_minus' 'pts_paint' 'pts_2nd_chance' 'pts_fast_break' 'largest_lead'\n",
      " 'games_played' 'win_percent']\n"
     ]
    }
   ],
   "source": [
    "# calculate games played in season, and win percentage\n",
    "games_played = []\n",
    "win_percent = []\n",
    "\n",
    "for _, row in team_data_df.iterrows():\n",
    "    wins, losses = (int(n) for n in row[\"wins_losses\"].split(\"-\"))\n",
    "    games_played.append(wins + losses)\n",
    "    win_percent.append(wins / (wins + losses))\n",
    "\n",
    "# update the dataframe\n",
    "team_data_df[\"games_played\"] = games_played\n",
    "team_data_df[\"win_percent\"] = win_percent\n",
    "team_data_df = team_data_df.drop(columns=[\"wins_losses\"])\n",
    "\n",
    "# check size and columns\n",
    "print(team_data_df.shape)\n",
    "print(team_data_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15429, 9)\n",
      "['season_id' 'game_id' 'game_date' 'team_id_home' 'team_id_away'\n",
      " 'home_vs_away' 'home_win' 'points_home' 'points_away']\n"
     ]
    }
   ],
   "source": [
    "# get list of games to predict\n",
    "list_games_query = f\"\"\"\n",
    "SELECT\n",
    "    season_id,\n",
    "    game_id,\n",
    "    game_date,\n",
    "    team_id_home,\n",
    "    team_id_away,\n",
    "    matchup_home AS home_vs_away,\n",
    "    CASE WHEN wl_home = 'W' THEN 1 ELSE 0 END AS home_win,\n",
    "    pts_home AS points_home,\n",
    "    pts_away AS points_away\n",
    "FROM game\n",
    "WHERE \n",
    "    season_id IN {season_ids};\n",
    "\"\"\"\n",
    "\n",
    "# load games into a dataframe\n",
    "games_df = pd.read_sql_query(sql=list_games_query, con=db)\n",
    "\n",
    "# check size and columns\n",
    "print(games_df.shape)\n",
    "print(games_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates\n",
    "team_data_df[\"date\"] = pd.to_datetime(team_data_df[\"date\"])\n",
    "games_df[\"game_date\"] = pd.to_datetime(games_df[\"game_date\"])\n",
    "\n",
    "# ensure all numeric columns have the float type\n",
    "tensor_columns = [\n",
    "    \"win\",\n",
    "    \"home\",\n",
    "    \"close_game\",\n",
    "    \"ot_count\",\n",
    "    \"q1_points\",\n",
    "    \"q2_points\",\n",
    "    \"q3_points\",\n",
    "    \"q4_points\",\n",
    "    \"ot_points\",\n",
    "    \"final_points\",\n",
    "    \"field_made\",\n",
    "    \"three_made\",\n",
    "    \"free_made\",\n",
    "    \"offensive_rebounds\",\n",
    "    \"defensive_rebounds\",\n",
    "    \"total_rebounds\",\n",
    "    \"assists\",\n",
    "    \"steals\",\n",
    "    \"blocks\",\n",
    "    \"turnovers\",\n",
    "    \"fouls\",\n",
    "    \"plus_minus\",\n",
    "    \"pts_paint\",\n",
    "    \"pts_2nd_chance\",\n",
    "    \"pts_fast_break\",\n",
    "    \"largest_lead\",\n",
    "    \"games_played\",\n",
    "    \"field_percent\",\n",
    "    \"three_percent\",\n",
    "    \"free_percent\",\n",
    "    \"win_percent\",\n",
    "]\n",
    "\n",
    "for column in tensor_columns:\n",
    "    team_data_df[column] = team_data_df[column].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation data from date: 2022-02-21 00:00:00\n",
      "final week example data from date: 2023-04-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# split training and evaluation data halfway through the 2021-22 season (all-star weekend)\n",
    "split_on_date = pd.Timestamp(\"2022-02-21\")\n",
    "print(f\"evaluation data from date: {split_on_date}\")\n",
    "\n",
    "# save final week of 2022-23 season data as an example\n",
    "final_week_date = pd.Timestamp(\"2023-04-04\")\n",
    "print(f\"final week example data from date: {final_week_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to work out current streak from list of results\n",
    "def current_streak(game_results: list[int], target: int) -> int:\n",
    "    if game_results[0] != target:\n",
    "        return 0\n",
    "\n",
    "    streak = 1\n",
    "    for g in game_results[1:]:\n",
    "        if g != target:\n",
    "            break\n",
    "        streak += 1\n",
    "    return streak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15429it [31:33,  8.15it/s] \n"
     ]
    }
   ],
   "source": [
    "# lists to track the various datasets\n",
    "training_data = []\n",
    "evaluation_data_half = []\n",
    "evaluation_data_full = []\n",
    "final_week_data = []\n",
    "training_streaks_short = []\n",
    "training_streaks_long = []\n",
    "evaluation_streaks_short = []\n",
    "evaluation_streaks_long = []\n",
    "\n",
    "\n",
    "# loop through each game, constructing the sample data from the team data\n",
    "for idx, game in tqdm(games_df.iterrows()):\n",
    "    home_team_games_df = (\n",
    "        team_data_df.loc[\n",
    "            (team_data_df[\"season_id\"] == game[\"season_id\"])\n",
    "            & (team_data_df[\"team_id\"] == game[\"team_id_home\"])\n",
    "            & (team_data_df[\"date\"] < game[\"game_date\"])\n",
    "        ]\n",
    "        .sort_values(by=\"date\")\n",
    "        .tail(10)\n",
    "    )\n",
    "\n",
    "    if len(home_team_games_df) < 10:\n",
    "        # skip if not enough previous data\n",
    "        continue\n",
    "\n",
    "    away_team_games_df = (\n",
    "        team_data_df.loc[\n",
    "            (team_data_df[\"season_id\"] == game[\"season_id\"])\n",
    "            & (team_data_df[\"team_id\"] == game[\"team_id_away\"])\n",
    "            & (team_data_df[\"date\"] < game[\"game_date\"])\n",
    "        ]\n",
    "        .sort_values(by=\"date\")\n",
    "        .tail(10)\n",
    "    )\n",
    "\n",
    "    if len(away_team_games_df) < 10:\n",
    "        # skip if not enough previous data\n",
    "        continue\n",
    "\n",
    "    home_team_games = []\n",
    "    home_team_opps = []\n",
    "    for _, row in home_team_games_df.iterrows():\n",
    "        home_team_games.append(row.to_list()[4:])\n",
    "        home_team_opps.append(\n",
    "            team_data_df.loc[\n",
    "                (team_data_df[\"game_id\"] == row[\"game_id\"])\n",
    "                & (team_data_df[\"team_id\"] != game[\"team_id_home\"])\n",
    "            ]\n",
    "            .iloc[0]\n",
    "            .to_list()[8:]\n",
    "        )\n",
    "\n",
    "    away_team_games = []\n",
    "    away_team_opps = []\n",
    "    for _, row in away_team_games_df.iterrows():\n",
    "        away_team_games.append(row.to_list()[4:])\n",
    "        away_team_opps.append(\n",
    "            team_data_df.loc[\n",
    "                (team_data_df[\"game_id\"] == row[\"game_id\"])\n",
    "                & (team_data_df[\"team_id\"] != game[\"team_id_away\"])\n",
    "            ]\n",
    "            .iloc[0]\n",
    "            .to_list()[8:]\n",
    "        )\n",
    "\n",
    "    combined = []\n",
    "    for a, b, c, d in zip(\n",
    "        home_team_games,\n",
    "        home_team_opps,\n",
    "        away_team_games,\n",
    "        away_team_opps,\n",
    "    ):\n",
    "        combined.append(a + b + c + d)\n",
    "\n",
    "    game[\"game_date\"] = game[\"game_date\"].strftime(\"%Y-%m-%d\")  # make date serializable\n",
    "    _game_dict = {\n",
    "        \"info\": game.to_dict(),\n",
    "        \"data\": combined,\n",
    "    }\n",
    "\n",
    "    home_results = [h[0] for h in home_team_games]\n",
    "    home_results.reverse()\n",
    "    away_results = [a[0] for a in away_team_games]\n",
    "    away_results.reverse()\n",
    "    _streaks = {\n",
    "        current_streak(home_results, 1 - game[\"home_win\"]),\n",
    "        current_streak(away_results, game[\"home_win\"]),\n",
    "    }\n",
    "\n",
    "    if pd.Timestamp(game[\"game_date\"]) < split_on_date:\n",
    "        training_data.append(_game_dict)\n",
    "\n",
    "        if any([s > 5 for s in _streaks]):\n",
    "            training_streaks_long.append(_game_dict)\n",
    "        if {3, 4} & _streaks:\n",
    "            training_streaks_short.append(_game_dict)\n",
    "\n",
    "    else:\n",
    "        if game[\"season_id\"] == \"22021\":\n",
    "            evaluation_data_half.append(_game_dict)\n",
    "        elif game[\"season_id\"] == \"22022\":\n",
    "            evaluation_data_full.append(_game_dict)\n",
    "\n",
    "        if any([s > 5 for s in _streaks]):\n",
    "            evaluation_streaks_long.append(_game_dict)\n",
    "        if {3, 4} & _streaks:\n",
    "            evaluation_streaks_short.append(_game_dict)\n",
    "\n",
    "    if pd.Timestamp(game[\"game_date\"]) > final_week_date:\n",
    "        final_week_data.append(_game_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 11581 training samples, 1398 evaluation samples, 42 examples, and 2600 streaks.\n"
     ]
    }
   ],
   "source": [
    "# create final few collections of datasets\n",
    "evaluation_data = evaluation_data_full + evaluation_data_half\n",
    "complete_data = evaluation_data + training_data\n",
    "all_streaks = (\n",
    "    training_streaks_long\n",
    "    + training_streaks_short\n",
    "    + evaluation_streaks_long\n",
    "    + evaluation_streaks_long\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Have {len(training_data)} training samples, \"\n",
    "    f\"{len(evaluation_data)} evaluation samples, \"\n",
    "    f\"{len(final_week_data)} examples, \"\n",
    "    f\"and {len(all_streaks)} streaks.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved df training_df with shape (11581, 2) to parquet/training_df.parquet\n",
      "Saved df evaluation_df_all with shape (1398, 2) to parquet/evaluation_df_all.parquet\n",
      "Saved df evaluation_df_half_21_22 with shape (347, 2) to parquet/evaluation_df_half_21_22.parquet\n",
      "Saved df evaluation_df_full_22_23 with shape (1051, 2) to parquet/evaluation_df_full_22_23.parquet\n",
      "Saved df complete_df with shape (12979, 2) to parquet/complete_df.parquet\n",
      "Saved df final_week_df with shape (42, 2) to parquet/final_week_df.parquet\n",
      "Saved df training_streaks_short_df with shape (1845, 2) to parquet/training_streaks_short_df.parquet\n",
      "Saved df training_streaks_long_df with shape (623, 2) to parquet/training_streaks_long_df.parquet\n",
      "Saved df evaluation_streaks_short_df with shape (239, 2) to parquet/evaluation_streaks_short_df.parquet\n",
      "Saved df evaluation_streaks_long_df with shape (66, 2) to parquet/evaluation_streaks_long_df.parquet\n"
     ]
    }
   ],
   "source": [
    "# check and save to file\n",
    "for _records, _name in [\n",
    "    (training_data, \"training_df\"),\n",
    "    (evaluation_data, \"evaluation_df_all\"),\n",
    "    (evaluation_data_half, \"evaluation_df_half_21_22\"),\n",
    "    (evaluation_data_full, \"evaluation_df_full_22_23\"),\n",
    "    (complete_data, \"complete_df\"),\n",
    "    (final_week_data, \"final_week_df\"),\n",
    "    (training_streaks_short, \"training_streaks_short_df\"),\n",
    "    (training_streaks_long, \"training_streaks_long_df\"),\n",
    "    (evaluation_streaks_short, \"evaluation_streaks_short_df\"),\n",
    "    (evaluation_streaks_long, \"evaluation_streaks_long_df\"),\n",
    "]:\n",
    "    _df = pd.DataFrame.from_records(_records)\n",
    "    _file = f\"parquet/{_name}.parquet\"\n",
    "    _df.to_parquet(_file)\n",
    "    print(f\"Saved df {_name} with shape {_df.shape} to {_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
